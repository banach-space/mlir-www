<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Dialects on MLIR</title><link>https://mlir.llvm.org/docs/Dialects/</link><description>Recent content in Dialects on MLIR</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 01 Jan 1970 00:00:00 +0000</lastBuildDate><atom:link href="https://mlir.llvm.org/docs/Dialects/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://mlir.llvm.org/docs/Dialects/DLTITransformOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/DLTITransformOps/</guid><description>source
transform.dlti.query (transform::QueryOp) Return attribute (as param) associated to key via DTLI
Syntax:
operation ::= `transform.dlti.query` $keys `at` $target attr-dict `:` functional-type(operands, results) This op queries data layout and target information associated to payload IR by way of the DLTI dialect.
A lookup is performed for the given keys at target op - or its closest interface-implementing ancestor - by way of the DLTIQueryInterface, which returns an attribute for a key.</description></item><item><title>'acc' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/OpenACCDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/OpenACCDialect/</guid><description>The acc dialect is an MLIR dialect for representing the OpenACC programming model. OpenACC is a standardized directive-based model which is used with C, C++, and Fortran to enable programmers to expose parallelism in their code. The descriptive approach used by OpenACC allows targeting of parallel multicore and accelerator targets like GPUs by giving the compiler the freedom of how to parallelize for specific architectures. OpenACC also provides the ability to optimize the parallelism through increasingly more prescriptive clauses.</description></item><item><title>'affine' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Affine/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Affine/</guid><description>This dialect provides a powerful abstraction for affine operations and analyses.
Polyhedral Structures Dimensions and Symbols Restrictions on Dimensions and Symbols Affine Expressions Affine Maps Semi-affine maps Integer Sets Operations affine.apply (affine::AffineApplyOp) affine.delinearize_index (affine::AffineDelinearizeIndexOp) affine.for (affine::AffineForOp) affine.if (affine::AffineIfOp) affine.load (affine::AffineLoadOp) affine.max (affine::AffineMaxOp) affine.min (affine::AffineMinOp) affine.parallel (affine::AffineParallelOp) affine.prefetch (affine::AffinePrefetchOp) affine.store (affine::AffineStoreOp) affine.vector_load (affine::AffineVectorLoadOp) affine.vector_store (affine::AffineVectorStoreOp) affine.yield (affine::AffineYieldOp) affine.dma_start (mlir::AffineDmaStartOp) affine.dma_wait (mlir::AffineDmaWaitOp) Polyhedral Structures MLIR uses techniques from polyhedral compilation to make dependence analysis and loop transformations efficient and reliable.</description></item><item><title>'amdgpu' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/AMDGPU/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/AMDGPU/</guid><description>The AMDGPU dialect provides wrappers around AMD-specific functionality and LLVM intrinsics. These wrappers should be used in conjunction with more generic dialects, such as gpu and vector, when generating LLVM IR that will eventually be executed on AMD hardware.
Operations amdgpu.dpp (amdgpu::DPPOp) amdgpu.ext_packed_fp8 (amdgpu::ExtPackedFp8Op) amdgpu.lds_barrier (amdgpu::LDSBarrierOp) amdgpu.mfma (amdgpu::MFMAOp) amdgpu.packed_stoch_round_fp8 (amdgpu::PackedStochRoundFp8Op) amdgpu.packed_trunc_2xfp8 (amdgpu::PackedTrunc2xFp8Op) amdgpu.raw_buffer_atomic_cmpswap (amdgpu::RawBufferAtomicCmpswapOp) amdgpu.raw_buffer_atomic_fadd (amdgpu::RawBufferAtomicFaddOp) amdgpu.raw_buffer_atomic_fmax (amdgpu::RawBufferAtomicFmaxOp) amdgpu.raw_buffer_atomic_smax (amdgpu::RawBufferAtomicSmaxOp) amdgpu.raw_buffer_atomic_umin (amdgpu::RawBufferAtomicUminOp) amdgpu.raw_buffer_load (amdgpu::RawBufferLoadOp) amdgpu.raw_buffer_store (amdgpu::RawBufferStoreOp) amdgpu.sched_barrier (amdgpu::SchedBarrierOp) amdgpu.wmma (amdgpu::WMMAOp) Attributes DPPPermAttr MFMAPermBAttr sched_barrier_opt_enumAttr Enums DPPPerm MFMAPermB sched_barrier_opt_enum Operations source</description></item><item><title>'amx' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/AMX/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/AMX/</guid><description>The Intel Advanced Matrix Extensions (AMX) provide a tile matrix multiply unit (TMUL), a tile control register (TILECFG), and eight tile registers TMM0 through TMM7 (TILEDATA).
This AMX dialect provides a bridge between MLIR concepts such as vectors and memrefs and the lower level LLVM IR support of AMX. The dialect is split into user-facing AMX ops (AMX_Op) and backend-facing intrinsic ops (AMX_IntrOp).
Note that since configuration changes (implicit at dialect level) are costly, it is highly recommended to use the AMX dialect on same-shaped vectors, at least within a single method.</description></item><item><title>'arith' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ArithOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ArithOps/</guid><description>The arith dialect is intended to hold basic integer and floating point mathematical operations. This includes unary, binary, and ternary arithmetic ops, bitwise and shift ops, cast ops, and compare ops. Operations in this dialect also accept vectors and tensors of integers or floats. The dialect assumes integers are represented by bitvectors with a two&amp;rsquo;s complement representation. Unless otherwise stated, the operations within this dialect propagate poison values, i.e., if any of its inputs are poison, then the output is poison.</description></item><item><title>'arm_neon' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ArmNeon/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ArmNeon/</guid><description>Operations arm_neon.2d.sdot (arm_neon::Sdot2dOp) arm_neon.intr.sdot (arm_neon::SdotOp) arm_neon.intr.smmla (arm_neon::SmmlaOp) arm_neon.intr.smull (arm_neon::SMullOp) arm_neon.intr.ummla (arm_neon::UmmlaOp) arm_neon.intr.usmmla (arm_neon::UsmmlaOp) Operations source
arm_neon.2d.sdot (arm_neon::Sdot2dOp) Sdot op
Syntax:
operation ::= `arm_neon.2d.sdot` $a `,` $b `,` $c attr-dict `:` type($b) `,` type($c) `to` type($res) The two input vectors b and c have a 2D shape, consisting of either 2 or 4 rows, each row having length 4. This operation computes the pair-wise dot-products of the rows of b and c and accumulates them with the corresponding entry of a:</description></item><item><title>'arm_sve' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ArmSVE/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ArmSVE/</guid><description>Basic dialect to target Arm SVE architectures This dialect contains the definitions necessary to target specific Arm SVE scalable vector operations.
Operations arm_sve.convert_from_svbool (arm_sve::ConvertFromSvboolOp) arm_sve.convert_to_svbool (arm_sve::ConvertToSvboolOp) arm_sve.intr.add (arm_sve::ScalableMaskedAddIIntrOp) arm_sve.intr.convert.from.svbool (arm_sve::ConvertFromSvboolIntrOp) arm_sve.intr.convert.to.svbool (arm_sve::ConvertToSvboolIntrOp) arm_sve.intr.fadd (arm_sve::ScalableMaskedAddFIntrOp) arm_sve.intr.fdiv (arm_sve::ScalableMaskedDivFIntrOp) arm_sve.intr.fmul (arm_sve::ScalableMaskedMulFIntrOp) arm_sve.intr.fsub (arm_sve::ScalableMaskedSubFIntrOp) arm_sve.intr.mul (arm_sve::ScalableMaskedMulIIntrOp) arm_sve.intr.psel (arm_sve::PselIntrOp) arm_sve.intr.sdiv (arm_sve::ScalableMaskedSDivIIntrOp) arm_sve.intr.sdot (arm_sve::SdotIntrOp) arm_sve.intr.smmla (arm_sve::SmmlaIntrOp) arm_sve.intr.sub (arm_sve::ScalableMaskedSubIIntrOp) arm_sve.intr.udiv (arm_sve::ScalableMaskedUDivIIntrOp) arm_sve.intr.udot (arm_sve::UdotIntrOp) arm_sve.intr.ummla (arm_sve::UmmlaIntrOp) arm_sve.intr.whilelt (arm_sve::WhileLTIntrOp) arm_sve.intr.zip.x2 (arm_sve::ZipX2IntrOp) arm_sve.intr.zip.x4 (arm_sve::ZipX4IntrOp) arm_sve.masked.addf (arm_sve::ScalableMaskedAddFOp) arm_sve.masked.addi (arm_sve::ScalableMaskedAddIOp) arm_sve.masked.divf (arm_sve::ScalableMaskedDivFOp) arm_sve.</description></item><item><title>'ArmSME' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ArmSME/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ArmSME/</guid><description>Basic dialect to target Arm SME.
This dialect defines custom and LLVM IR intrinsic operations that are used to target Arm Scalable Matrix Extension. Through the available conversion and ArmSME passes you can, for example, lower a linalg.matmul operation to Arm SME FMOPA (floating-point outer product) operations. See one of the in-tree end-to-end integration tests for reference:
Linalg/CPU/ArmSME/matmul.mlir Vector/CPU/ArmSME/outerproduct-f64.mlir In order to run ArmSME integration tests, include these flags in the CMake invocation when configuring LLVM and MLIR:</description></item><item><title>'async' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/AsyncDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/AsyncDialect/</guid><description>Types and operations for async dialect This dialect contains operations for modeling asynchronous execution.
Operations async.add_to_group (async::AddToGroupOp) async.await (async::AwaitOp) async.await_all (async::AwaitAllOp) async.call (async::CallOp) async.coro.begin (async::CoroBeginOp) async.coro.end (async::CoroEndOp) async.coro.free (async::CoroFreeOp) async.coro.id (async::CoroIdOp) async.coro.save (async::CoroSaveOp) async.coro.suspend (async::CoroSuspendOp) async.create_group (async::CreateGroupOp) async.execute (async::ExecuteOp) async.func (async::FuncOp) async.return (async::ReturnOp) async.runtime.add_ref (async::RuntimeAddRefOp) async.runtime.add_to_group (async::RuntimeAddToGroupOp) async.runtime.await (async::RuntimeAwaitOp) async.runtime.await_and_resume (async::RuntimeAwaitAndResumeOp) async.runtime.create (async::RuntimeCreateOp) async.runtime.create_group (async::RuntimeCreateGroupOp) async.runtime.drop_ref (async::RuntimeDropRefOp) async.runtime.is_error (async::RuntimeIsErrorOp) async.runtime.load (async::RuntimeLoadOp) async.runtime.num_worker_threads (async::RuntimeNumWorkerThreadsOp) async.runtime.resume (async::RuntimeResumeOp) async.runtime.set_available (async::RuntimeSetAvailableOp) async.runtime.set_error (async::RuntimeSetErrorOp) async.</description></item><item><title>'bufferization' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/BufferizationOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/BufferizationOps/</guid><description>Bufferization in MLIR is the process of converting the tensor type to the memref type. Simply put, bufferization is the process of converting computations on the mathematical tensor construct to computations on physical memory buffers. The bufferization dialect contains operations/interfaces specific to the bufferization passes.
An overview of the bufferization infrastructure and important conceptual details related to using the MLIR dialect conversion infrastructure can be found in bufferization and ownership-based buffer deallocation.</description></item><item><title>'cf' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ControlFlowDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ControlFlowDialect/</guid><description>This dialect contains low-level, i.e. non-region based, control flow constructs. These constructs generally represent control flow directly on SSA blocks of a control flow graph.
Operations cf.assert (cf::AssertOp) cf.br (cf::BranchOp) cf.cond_br (cf::CondBranchOp) cf.switch (cf::SwitchOp) Operations source
cf.assert (cf::AssertOp) Assert operation with message attribute
Syntax:
operation ::= `cf.assert` $arg `,` $msg attr-dict Assert operation at runtime with single boolean operand and an error message attribute. If the argument is true this operation has no effect.</description></item><item><title>'complex' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ComplexOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ComplexOps/</guid><description>The complex dialect is intended to hold complex numbers creation and arithmetic ops.
Operations complex.abs (complex::AbsOp) complex.add (complex::AddOp) complex.angle (complex::AngleOp) complex.atan2 (complex::Atan2Op) complex.bitcast (complex::BitcastOp) complex.conj (complex::ConjOp) complex.constant (complex::ConstantOp) complex.cos (complex::CosOp) complex.create (complex::CreateOp) complex.div (complex::DivOp) complex.eq (complex::EqualOp) complex.exp (complex::ExpOp) complex.expm1 (complex::Expm1Op) complex.im (complex::ImOp) complex.log (complex::LogOp) complex.log1p (complex::Log1pOp) complex.mul (complex::MulOp) complex.neg (complex::NegOp) complex.neq (complex::NotEqualOp) complex.pow (complex::PowOp) complex.re (complex::ReOp) complex.rsqrt (complex::RsqrtOp) complex.sign (complex::SignOp) complex.sin (complex::SinOp) complex.sqrt (complex::SqrtOp) complex.sub (complex::SubOp) complex.tan (complex::TanOp) complex.tanh (complex::TanhOp) Enums CmpFPredicate CmpIPredicate IntegerOverflowFlags RoundingMode AtomicRMWKind FastMathFlags Operations source</description></item><item><title>'dlti' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/DLTIDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/DLTIDialect/</guid><description>The Data Layout and Target Information (DLTI) dialect is intended to hold attributes and other components pertaining to descriptions of in-memory data layout and compilation targets.
Attributes DataLayoutEntryAttr DataLayoutSpecAttr MapAttr Attributes DataLayoutEntryAttr An attribute to represent an entry of a data layout specification.
A data layout entry attribute is a key-value pair where the key is a type or an identifier and the value is another attribute. These entries form a data layout specification.</description></item><item><title>'emitc' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/EmitC/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/EmitC/</guid><description>Dialect to generate C/C++ from MLIR. The EmitC dialect allows to convert operations from other MLIR dialects to EmitC ops. Those can be translated to C/C++ via the Cpp emitter.
The following convention is followed:
If template arguments are passed to an emitc.call_opaque operation, C++ is generated. If tensors are used, C++ is generated. If multiple return values are used within in a functions or an emitc.call_opaque operation, C++11 is required.</description></item><item><title>'func' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Func/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Func/</guid><description>This dialect provides documentation for operations within the Func dialect.
This dialect contains operations surrounding high order function abstractions, such as calls.
Please post an RFC on the forum before adding or changing any operation in this dialect.
Operations func.call_indirect (func::CallIndirectOp) func.call (func::CallOp) func.constant (func::ConstantOp) func.func (func::FuncOp) func.return (func::ReturnOp) Operations source
func.call_indirect (func::CallIndirectOp) Indirect call operation
Syntax:
operation ::= `func.call_indirect` $callee `(` $callee_operands `)` attr-dict `:` type($callee) The func.call_indirect operation represents an indirect call to a value of function type.</description></item><item><title>'gpu' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/GPU/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/GPU/</guid><description>Note: this dialect is more likely to change than others in the near future; use with caution.
This dialect provides middle-level abstractions for launching GPU kernels following a programming model similar to that of CUDA or OpenCL. It provides abstractions for kernel invocations (and may eventually provide those for device management) that are not present at the lower level (e.g., as LLVM IR intrinsics for GPUs). Its goal is to abstract away device- and driver-specific manipulations to launch a GPU kernel and provide a simple path towards GPU execution from MLIR.</description></item><item><title>'index' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/IndexOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/IndexOps/</guid><description>The Index dialect The Index dialect contains operations for manipulating values of the builtin index type. The index type models target-specific values of pointer width, like intptr_t. Index values are typically used as loop bounds, array subscripts, tensor dimensions, etc.
The operations in this dialect operate exclusively on scalar index types. The dialect and its operations treat the index type as signless and contains signed and unsigned versions of certain operations where the distinction is meaningful.</description></item><item><title>'irdl' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/IRDL/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/IRDL/</guid><description>IR Definition Language Dialect IRDL is an SSA-based declarative representation of dynamic dialects. It allows the definition of dialects, operations, attributes, and types, with a declarative description of their verifiers. IRDL code is meant to be generated and not written by hand. As such, the design focuses on ease of generation/analysis instead of ease of writing/reading.
Users can define a new dialect with irdl.dialect, operations with irdl.operation, types with irdl.</description></item><item><title>'llvm' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/LLVM/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/LLVM/</guid><description>This dialect maps LLVM IR into MLIR by defining the corresponding operations and types. LLVM IR metadata is usually represented as MLIR attributes, which offer additional structure verification.
We use &amp;ldquo;LLVM IR&amp;rdquo; to designate the intermediate representation of LLVM and &amp;ldquo;LLVM dialect&amp;rdquo; or &amp;ldquo;LLVM IR dialect&amp;rdquo; to refer to this MLIR dialect.
Unless explicitly stated otherwise, the semantics of the LLVM dialect operations must correspond to the semantics of LLVM IR instructions and any divergence is considered a bug.</description></item><item><title>'math' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/MathOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MathOps/</guid><description>The math dialect is intended to hold mathematical operations on integer and floating types beyond simple arithmetics. Each operation works on scalar, vector or tensor type. On vector and tensor type operations apply elementwise unless explicitly specified otherwise. As an example, the floating point absolute value can be expressed as:
// Scalar absolute value. %a = math.absf %b : f64 // Vector elementwise absolute value. %f = math.absf %g : vector&amp;lt;4xf32&amp;gt; // Tensor elementwise absolute value.</description></item><item><title>'memref' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/MemRef/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MemRef/</guid><description>This dialect provides documentation for operations within the MemRef dialect.
Please post an RFC on the forum before adding or changing any operation in this dialect.
Operations memref.assume_alignment (memref::AssumeAlignmentOp) memref.atomic_rmw (memref::AtomicRMWOp) memref.atomic_yield (memref::AtomicYieldOp) memref.copy (memref::CopyOp) memref.generic_atomic_rmw (memref::GenericAtomicRMWOp) memref.load (memref::LoadOp) memref.alloc (memref::AllocOp) memref.alloca (memref::AllocaOp) memref.alloca_scope (memref::AllocaScopeOp) memref.alloca_scope.return (memref::AllocaScopeReturnOp) memref.cast (memref::CastOp) memref.collapse_shape (memref::CollapseShapeOp) memref.dealloc (memref::DeallocOp) memref.dim (memref::DimOp) memref.dma_start (memref::DmaStartOp) memref.dma_wait (memref::DmaWaitOp) memref.expand_shape (memref::ExpandShapeOp) memref.extract_aligned_pointer_as_index (memref::ExtractAlignedPointerAsIndexOp) memref.extract_strided_metadata (memref::ExtractStridedMetadataOp) memref.get_global (memref::GetGlobalOp) memref.global (memref::GlobalOp) memref.memory_space_cast (memref::MemorySpaceCastOp) memref.</description></item><item><title>'mesh' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Mesh/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Mesh/</guid><description>The mesh dialect contains a set of attributes, operations and interfaces that are useful for representing sharding and communication on a device mesh cluster.
Collective Communication Operations Device groups In-group Device Purity Operations mesh.all_gather (mesh::AllGatherOp) mesh.all_reduce (mesh::AllReduceOp) mesh.all_slice (mesh::AllSliceOp) mesh.all_to_all (mesh::AllToAllOp) mesh.broadcast (mesh::BroadcastOp) mesh.gather (mesh::GatherOp) mesh.mesh (mesh::MeshOp) mesh.mesh_shape (mesh::MeshShapeOp) mesh.process_linear_index (mesh::ProcessLinearIndexOp) mesh.process_multi_index (mesh::ProcessMultiIndexOp) mesh.recv (mesh::RecvOp) mesh.reduce (mesh::ReduceOp) mesh.reduce_scatter (mesh::ReduceScatterOp) mesh.scatter (mesh::ScatterOp) mesh.send (mesh::SendOp) mesh.shard (mesh::ShardOp) mesh.shard_shape (mesh::ShardShapeOp) mesh.sharding (mesh::ShardingOp) mesh.shift (mesh::ShiftOp) mesh.</description></item><item><title>'ml_program' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/MLProgramOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MLProgramOps/</guid><description>The MLProgram dialect contains structural operations and types for defining a compiled Machine-Learning program, as created from common ML frameworks, such as TensorFlow, PyTorch, JAX, etc. It does not itself define computation ops common to such frameworks but establishes a common programming model for establishing modules, functions, globals and memory model components appropriate for such an abstract level of detail.
This dialect is under active development, and while stability is an eventual goal, it is not guaranteed at this juncture.</description></item><item><title>'mpi' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/MPI/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MPI/</guid><description>This dialect models the Message Passing Interface (MPI), version 4.0. It is meant to serve as an interfacing dialect that is targeted by higher-level dialects. The MPI dialect itself can be lowered to multiple MPI implementations and hide differences in ABI. The dialect models the functions of the MPI specification as close to 1:1 as possible while preserving SSA value semantics where it makes sense, and uses memref types instead of bare pointers.</description></item><item><title>'nvgpu' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/NVGPU/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/NVGPU/</guid><description>The NVGPU dialect provides a bridge between higher-level target-agnostic dialects (GPU and Vector) and the lower-level target-specific dialect (LLVM IR based NVVM dialect) for NVIDIA GPUs. This allow representing PTX specific operations while using MLIR high level dialects such as Memref and Vector for memory and target-specific register operands, respectively.
Operations nvgpu.device_async_copy (nvgpu::DeviceAsyncCopyOp) nvgpu.device_async_create_group (nvgpu::DeviceAsyncCreateGroupOp) nvgpu.device_async_wait (nvgpu::DeviceAsyncWaitOp) nvgpu.ldmatrix (nvgpu::LdMatrixOp) nvgpu.mbarrier.arrive (nvgpu::MBarrierArriveOp) nvgpu.mbarrier.arrive.expect_tx (nvgpu::MBarrierArriveExpectTxOp) nvgpu.mbarrier.arrive.nocomplete (nvgpu::MBarrierArriveNoCompleteOp) nvgpu.mbarrier.create (nvgpu::MBarrierCreateOp) nvgpu.mbarrier.init (nvgpu::MBarrierInitOp) nvgpu.</description></item><item><title>'nvvm' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/NVVMDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/NVVMDialect/</guid><description>Operations nvvm.bar.warp.sync (NVVM::SyncWarpOp) nvvm.barrier (NVVM::BarrierOp) nvvm.barrier.arrive (NVVM::BarrierArriveOp) nvvm.barrier0 (NVVM::Barrier0Op) nvvm.breakpoint (NVVM::Breakpoint) nvvm.cluster.arrive (NVVM::ClusterArriveOp) nvvm.cluster.arrive.relaxed (NVVM::ClusterArriveRelaxedOp) nvvm.cluster.wait (NVVM::ClusterWaitOp) nvvm.cp.async.bulk.commit.group (NVVM::CpAsyncBulkCommitGroupOp) nvvm.cp.async.bulk.tensor.global.shared.cta (NVVM::CpAsyncBulkTensorSharedCTAToGlobalOp) nvvm.cp.async.bulk.tensor.shared.cluster.global (NVVM::CpAsyncBulkTensorGlobalToSharedClusterOp) nvvm.cp.async.bulk.wait_group (NVVM::CpAsyncBulkWaitGroupOp) nvvm.cp.async.commit.group (NVVM::CpAsyncCommitGroupOp) nvvm.cp.async.mbarrier.arrive (NVVM::CpAsyncMBarrierArriveOp) nvvm.cp.async.mbarrier.arrive.shared (NVVM::CpAsyncMBarrierArriveSharedOp) nvvm.cp.async.shared.global (NVVM::CpAsyncOp) nvvm.cp.async.wait.group (NVVM::CpAsyncWaitGroupOp) nvvm.elect.sync (NVVM::ElectSyncOp) nvvm.fence.mbarrier.init (NVVM::FenceMbarrierInitOp) nvvm.fence.proxy (NVVM::FenceProxyOp) nvvm.fence.proxy.acquire (NVVM::FenceProxyAcquireOp) nvvm.fence.proxy.release (NVVM::FenceProxyReleaseOp) nvvm.fence.sc.cluster (NVVM::FenceScClusterOp) nvvm.ldmatrix (NVVM::LdMatrixOp) nvvm.mbarrier.arrive (NVVM::MBarrierArriveOp) nvvm.mbarrier.arrive.expect_tx (NVVM::MBarrierArriveExpectTxOp) nvvm.mbarrier.arrive.expect_tx.shared (NVVM::MBarrierArriveExpectTxSharedOp) nvvm.mbarrier.arrive.nocomplete (NVVM::MBarrierArriveNocompleteOp) nvvm.mbarrier.arrive.nocomplete.shared (NVVM::MBarrierArriveNocompleteSharedOp) nvvm.mbarrier.arrive.shared (NVVM::MBarrierArriveSharedOp) nvvm.mbarrier.init (NVVM::MBarrierInitOp) nvvm.mbarrier.init.shared (NVVM::MBarrierInitSharedOp) nvvm.mbarrier.inval (NVVM::MBarrierInvalOp) nvvm.mbarrier.inval.shared (NVVM::MBarrierInvalSharedOp) nvvm.</description></item><item><title>'pdl_interp' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/PDLInterpOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/PDLInterpOps/</guid><description>Interpreted pattern execution dialect The PDL Interpreter dialect provides a lower level abstraction compared to the PDL dialect, and is targeted towards low level optimization and interpreter code generation. The dialect operations encapsulates low-level pattern match and rewrite &amp;ldquo;primitives&amp;rdquo;, such as navigating the IR (Operation::getOperand), creating new operations (OpBuilder::create), etc. Many of the operations within this dialect also fuse branching control flow with some form of a predicate comparison operation.</description></item><item><title>'pdl' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/PDLOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/PDLOps/</guid><description>High level pattern definition dialect PDL presents a high level abstraction for the rewrite pattern infrastructure available in MLIR. This abstraction allows for representing patterns transforming MLIR, as MLIR. This allows for applying all of the benefits that the general MLIR infrastructure provides, to the infrastructure itself. This means that pattern matching can be more easily verified for correctness, targeted by frontends, and optimized.
PDL abstracts over various different aspects of patterns and core MLIR data structures.</description></item><item><title>'polynomial' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/PolynomialDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/PolynomialDialect/</guid><description>The Polynomial dialect defines single-variable polynomial types and operations.
The simplest use of polynomial is to represent mathematical operations in a polynomial ring R[x], where R is another MLIR type like i32.
More generally, this dialect supports representing polynomial operations in a quotient ring R[X]/(f(x)) for some statically fixed polynomial f(x). Two polyomials p(x), q(x) are considered equal in this ring if they have the same remainder when dividing by f(x).</description></item><item><title>'ptr' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/PtrOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/PtrOps/</guid><description>Pointer dialect
Attributes SpecAttr Types PtrType Attributes SpecAttr ptr data layout spec
Syntax:
#ptr.spec&amp;lt; uint32_t, # size uint32_t, # abi uint32_t, # preferred uint32_t # index &amp;gt; Defines the data layout spec for a pointer type. This attribute has 4 fields:
[Required] size: size of the pointer in bits. [Required] abi: ABI-required alignment for the pointer in bits. [Required] preferred: preferred alignment for the pointer in bits. [Optional] index: bitwidth that should be used when performing index computations for the type.</description></item><item><title>'quant' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/QuantDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/QuantDialect/</guid><description>The quant dialect offers a framework for defining and manipulating quantized values. Central to this framework is the !quant.uniform data type, used to represent quantized values. This dialect also provides a suite of operations to handle and convert quantized values between their original floating-point representations and the optimized, lower bit-width integer representations. The quant dialect is instrumented with transformation passes to lower these operations into other core MLIR dialects, while also flattening all occurrences of quantized types into their integer counterparts.</description></item><item><title>'rocdl' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ROCDLDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ROCDLDialect/</guid><description>Operations rocdl.ballot (ROCDL::BallotOp) rocdl.barrier (ROCDL::BarrierOp) rocdl.cvt.f32.bf8 (ROCDL::CvtF32Bf8Op) rocdl.cvt.f32.fp8 (ROCDL::CvtF32Fp8Op) rocdl.cvt.pk.bf8.f32 (ROCDL::CvtPkBf8F32Op) rocdl.cvt.pk.fp8.f32 (ROCDL::CvtPkFp8F32Op) rocdl.cvt.pkrtz (ROCDL::CvtPkRtz) rocdl.cvt.sr.bf8.f32 (ROCDL::CvtSrBf8F32Op) rocdl.cvt.sr.fp8.f32 (ROCDL::CvtSrFp8F32Op) rocdl.ds_bpermute (ROCDL::DsBpermuteOp) rocdl.ds_swizzle (ROCDL::DsSwizzleOp) rocdl.grid.dim.x (ROCDL::GridDimXOp) rocdl.grid.dim.z (ROCDL::GridDimZOp) rocdl.workgroup.dim.y (ROCDL::BlockDimYOp) rocdl.workgroup.id.x (ROCDL::BlockIdXOp) rocdl.workgroup.id.z (ROCDL::BlockIdZOp) rocdl.workitem.id.y (ROCDL::ThreadIdYOp) Attributes ROCDLTargetAttr Operations source
rocdl.ballot (ROCDL::BallotOp) Vote across thread group
Syntax:
operation ::= `rocdl.ballot` $pred attr-dict `:` type($res) Ballot provides a bit mask containing the 1-bit predicate value from each lane. The nth bit of the result contains the 1 bit contributed by the nth warp lane.</description></item><item><title>'scf' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/SCFDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/SCFDialect/</guid><description>The scf (structured control flow) dialect contains operations that represent control flow constructs such as if and for. Being structured means that the control flow has a structure unlike, for example, gotos or asserts. Unstructured control flow operations are located in the cf (control flow) dialect.
Originally, this dialect was developed as a common lowering stage for the affine and linalg dialects. Both convert to SCF loops instead of targeting branch-based CFGs directly.</description></item><item><title>'shape' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/ShapeDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/ShapeDialect/</guid><description>Description of operations &amp;amp; types within the Shape dialect as well as their usage.
Types and operations for shape dialect This dialect contains operations for shape inference.
Note: Unless explicitly stated, all functions that return a shape and take shapes as input, return the invalid shape if one of its operands is an invalid shape. This avoids flagging multiple errors for one verification failure. The dialect itself does not specify how errors should be combined (there are multiple different options, from always choosing first operand, concatting etc.</description></item><item><title>'sparse_tensor' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/SparseTensorOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/SparseTensorOps/</guid><description>The SparseTensor dialect supports all the attributes, types, operations, and passes that are required to make sparse tensor types first class citizens within the MLIR compiler infrastructure. The dialect forms a bridge between high-level operations on sparse tensors types and lower-level operations on the actual sparse storage schemes consisting of positions, coordinates, and values. Lower-level support may consist of fully generated code or may be provided by means of a small sparse runtime support library.</description></item><item><title>'tensor' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/TensorOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/TensorOps/</guid><description>The tensor dialect is intended to hold core tensor creation and manipulation ops, which are not strongly associated with any particular other dialect or domain abstraction. The aim for ops in this dialect is that they make sense for any tensor element type. When this is not the case, the op is left to live in other dialects. Examples of element types that could be supported by the tensor dialect include:</description></item><item><title>'ub' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/UBOps/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/UBOps/</guid><description>Operations ub.poison (ub::PoisonOp) Attributes PoisonAttr Operations source
ub.poison (ub::PoisonOp) Poisoned constant operation.
Syntax:
operation ::= `ub.poison` attr-dict (`&amp;lt;` $value^ `&amp;gt;`)? `:` type($result) The poison operation materializes a compile-time poisoned constant value to indicate deferred undefined behavior. value attribute is needed to indicate an optional additional poison semantics (e.g. partially poisoned vectors), default value indicates results is fully poisoned.
Examples:
// Short form %0 = ub.poison : i32 // Long form %1 = ub.</description></item><item><title>'vcix' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/VCIXDialect/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/VCIXDialect/</guid><description>The SiFive Vector Coprocessor Interface (VCIX) provides a flexible mechanism to extend application processors with custom coprocessors and variable-latency arithmetic units. The interface offers throughput comparable to that of standard RISC-V vector instructions. To accelerate performance, system designers may use VCIX as a low-latency, high-throughput interface to a coprocessor
https://www.sifive.com/document-file/sifive-vector-coprocessor-interface-vcix-software
Operations vcix.v.iv (vcix::BinaryImmOp) vcix.v.sv (vcix::BinaryOp) Operations source
vcix.v.iv (vcix::BinaryImmOp) Binary VCIX operation with an immediate second operand
Binary VCIX operation with an immediate second operand.</description></item><item><title>'vector' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Vector/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Vector/</guid><description>Positioning in the Codegen Infrastructure Components of a Generic Retargetable Vector-Level Dialect Short Description of the Existing Infrastructure LLVM level Hardware Vector Ops Virtual Vector Ops Virtual Vector Rewrite Patterns Virtual Vector to Hardware Vector Lowering Rationale Hardware as vector Machines of Minimum Granularity Transformations Problems Avoided The Big Out-Of-Scope Piece: Automatic Vectorization Bikeshed Naming Discussion 0D Vectors LLVM Lowering Tradeoffs Alternatives For Lowering an n-D Vector Type to LLVM Constraints Inherited from LLVM (see LangRef) Nested Aggregate Flattened 1-D Vector Type Discussion Relationship to LLVM matrix type proposal.</description></item><item><title>'x86vector' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/X86Vector/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/X86Vector/</guid><description>Operations x86vector.avx.intr.dot (x86vector::DotOp) x86vector.avx.intr.dp.ps.256 (x86vector::DotIntrOp) x86vector.avx.intr.rsqrt.ps.256 (x86vector::RsqrtIntrOp) x86vector.avx.rsqrt (x86vector::RsqrtOp) x86vector.avx512.intr.mask.compress (x86vector::MaskCompressIntrOp) x86vector.avx512.intr.mask.rndscale.pd.512 (x86vector::MaskRndScalePDIntrOp) x86vector.avx512.intr.mask.rndscale.ps.512 (x86vector::MaskRndScalePSIntrOp) x86vector.avx512.intr.mask.scalef.pd.512 (x86vector::MaskScaleFPDIntrOp) x86vector.avx512.intr.mask.scalef.ps.512 (x86vector::MaskScaleFPSIntrOp) x86vector.avx512.intr.vp2intersect.d.512 (x86vector::Vp2IntersectDIntrOp) x86vector.avx512.intr.vp2intersect.q.512 (x86vector::Vp2IntersectQIntrOp) x86vector.avx512.mask.compress (x86vector::MaskCompressOp) x86vector.avx512.mask.rndscale (x86vector::MaskRndScaleOp) x86vector.avx512.mask.scalef (x86vector::MaskScaleFOp) x86vector.avx512.vp2intersect (x86vector::Vp2IntersectOp) Operations source
x86vector.avx.intr.dot (x86vector::DotOp) Dot
Syntax:
operation ::= `x86vector.avx.intr.dot` $a `,` $b attr-dict `:` type($res) Computes the 4-way dot products of the lower and higher parts of the source vectors and broadcasts the two results to the lower and higher elements of the destination vector, respectively.</description></item><item><title>'xegpu' Dialect</title><link>https://mlir.llvm.org/docs/Dialects/XeGPU/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/XeGPU/</guid><description>The XeGPU dialect that models Intel GPU&amp;rsquo;s ISA The XeGPU dialect models Intel Xe ISA semantics but works at vector and TensorDesc data type. It provides 1:1 mappings to match Xe instructions like DPAS and 2D block load. The matrix size being processed at this level exactly matches the hardware instructions or the intrinsic supported by the lower-level GPU compiler.
Operations xegpu.alloc_nbarrier (xegpu::AllocNbarrierOp) xegpu.atomic_rmw (xegpu::AtomicRMWOp) xegpu.create_nd_tdesc (xegpu::CreateNdDescOp) xegpu.create_tdesc (xegpu::CreateDescOp) xegpu.</description></item><item><title>Builtin Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Builtin/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Builtin/</guid><description>The builtin dialect contains a core set of Attributes, Operations, and Types that have wide applicability across a very large number of domains and abstractions. Many of the components of this dialect are also instrumental in the implementation of the core IR. As such, this dialect is implicitly loaded in every MLIRContext, and available directly to all users of MLIR.
Given the far-reaching nature of this dialect and the fact that MLIR is extensible by design, any potential additions are heavily scrutinized.</description></item><item><title>OpInterface definitions</title><link>https://mlir.llvm.org/docs/Dialects/MatchOpInterfaces/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/MatchOpInterfaces/</guid><description> MatchOpInterface (MatchOpInterface) Methods:</description></item><item><title>SPIR-V Dialect</title><link>https://mlir.llvm.org/docs/Dialects/SPIR-V/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/SPIR-V/</guid><description>This document describes the design of the SPIR-V dialect in MLIR. It lists various design choices we made for modeling different SPIR-V mechanisms, and their rationale.
This document also explains in a high-level manner how different components are organized and implemented in the code and gives steps to follow for extending them.
This document assumes familiarity with SPIR-V. SPIR-V is the Khronos Groupâ€™s binary intermediate language for representing graphics shaders and compute kernels.</description></item><item><title>Tensor Operator Set Architecture (TOSA) Dialect</title><link>https://mlir.llvm.org/docs/Dialects/TOSA/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/TOSA/</guid><description>Rationale TOSA and Tensor Level Expressiveness Complete Minimal Numerical Precision TOSA Operator Rationale COND_IF and WHILE_LOOP Using TOSA In A Compiler Quantization Parameters in Ops vs Tensors Operation definitions tosa.abs (mlir::tosa::AbsOp) tosa.add (mlir::tosa::AddOp) tosa.apply_scale (mlir::tosa::ApplyScaleOp) tosa.argmax (mlir::tosa::ArgMaxOp) tosa.arithmetic_right_shift (mlir::tosa::ArithmeticRightShiftOp) tosa.avg_pool2d (mlir::tosa::AvgPool2dOp) tosa.bitwise_and (mlir::tosa::BitwiseAndOp) tosa.bitwise_not (mlir::tosa::BitwiseNotOp) tosa.bitwise_or (mlir::tosa::BitwiseOrOp) tosa.bitwise_xor (mlir::tosa::BitwiseXorOp) tosa.cast (mlir::tosa::CastOp) tosa.ceil (mlir::tosa::CeilOp) tosa.clamp (mlir::tosa::ClampOp) tosa.clz (mlir::tosa::ClzOp) tosa.concat (mlir::tosa::ConcatOp) tosa.const (mlir::tosa::ConstOp) tosa.conv2d (mlir::tosa::Conv2DOp) tosa.conv3d (mlir::tosa::Conv3DOp) tosa.cos (mlir::tosa::CosOp) tosa.custom (mlir::tosa::CustomOp) tosa.</description></item><item><title>Transform Dialect</title><link>https://mlir.llvm.org/docs/Dialects/Transform/</link><pubDate>Thu, 01 Jan 1970 00:00:00 +0000</pubDate><guid>https://mlir.llvm.org/docs/Dialects/Transform/</guid><description>Fine-grain transformation control dialect. See tutorial for more introductory information.
Overview Dialect Extension Mechanism Side Effects Execution Model Handle Invalidation Intended Use and Integrations Effects on the Infrastructure Type Definitions AffineMapParamType AnyOpType AnyParamType AnyValueType OperationType ParamType TypeParamType Core Operations transform.alternatives (transform::AlternativesOp) transform.annotate (transform::AnnotateOp) transform.apply_patterns.canonicalization (transform::ApplyCanonicalizationPatternsOp) transform.apply_cse (transform::ApplyCommonSubexpressionEliminationOp) transform.apply_conversion_patterns (transform::ApplyConversionPatternsOp) transform.apply_dce (transform::ApplyDeadCodeEliminationOp) transform.apply_licm (transform::ApplyLoopInvariantCodeMotionOp) transform.apply_patterns (transform::ApplyPatternsOp) transform.apply_registered_pass (transform::ApplyRegisteredPassOp) transform.apply_conversion_patterns.dialect_to_llvm (transform::ApplyToLLVMConversionPatternsOp) transform.cast (transform::CastOp) transform.collect_matching (transform::CollectMatchingOp) transform.foreach_match (transform::ForeachMatchOp) transform.foreach (transform::ForeachOp) transform.get_consumers_of_result (transform::GetConsumersOfResult) transform.get_defining_op (transform::GetDefiningOp) transform.</description></item></channel></rss>